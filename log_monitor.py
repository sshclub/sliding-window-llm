#!/usr/bin/env python3
"""
ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ë¡œê·¸ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„
"""

import os
import time
import json
import threading
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import re
from collections import defaultdict, deque

class LogMonitor:
    def __init__(self, log_file: str = "realtime.log"):
        self.log_file = log_file
        self.running = False
        self.last_position = 0
        self.analysis_interval = 30  # 30ì´ˆë§ˆë‹¤ ë¶„ì„
        self.window_size = 50  # ë¶„ì„í•  ë¡œê·¸ ë¼ì¸ ìˆ˜
        
        # í†µê³„
        self.stats = {
            "total_logs": 0,
            "by_level": defaultdict(int),
            "by_service": defaultdict(int),
            "error_count": 0,
            "critical_count": 0,
            "last_analysis": None,
            "analysis_count": 0
        }
        
        # ìµœê·¼ ë¡œê·¸ ì €ì¥ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
        self.recent_logs = deque(maxlen=1000)
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = []
        
        # ì•Œë¦¼ ì„ê³„ê°’
        self.thresholds = {
            "error_rate": 0.1,  # 10% ì´ìƒ ì—ëŸ¬
            "critical_count": 5,  # 5ê°œ ì´ìƒ í¬ë¦¬í‹°ì»¬
            "analysis_trigger": 20  # 20ê°œ ì´ìƒ ìƒˆ ë¡œê·¸
        }
    
    def parse_log_line(self, line: str) -> Optional[Dict]:
        """ë¡œê·¸ ë¼ì¸ íŒŒì‹±"""
        # í˜•ì‹: YYYY-MM-DD HH:MM:SS LEVEL [SERVICE] MESSAGE
        pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) \[(\w+)\] (.+)'
        match = re.match(pattern, line.strip())
        
        if match:
            timestamp_str, level, service, message = match.groups()
            timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
            
            return {
                "timestamp": timestamp,
                "level": level,
                "service": service,
                "message": message,
                "raw": line.strip()
            }
        return None
    
    def read_new_logs(self) -> List[Dict]:
        """ìƒˆë¡œìš´ ë¡œê·¸ ì½ê¸°"""
        new_logs = []
        
        try:
            if not os.path.exists(self.log_file):
                return new_logs
            
            with open(self.log_file, 'r', encoding='utf-8', errors='ignore') as f:
                f.seek(self.last_position)
                lines = f.readlines()
                self.last_position = f.tell()
            
            for line in lines:
                parsed = self.parse_log_line(line)
                if parsed:
                    new_logs.append(parsed)
                    self.recent_logs.append(parsed)
            
        except Exception as e:
            print(f"âŒ ë¡œê·¸ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        return new_logs
    
    def update_stats(self, logs: List[Dict]):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        for log in logs:
            self.stats["total_logs"] += 1
            self.stats["by_level"][log["level"]] += 1
            self.stats["by_service"][log["service"]] += 1
            
            if log["level"] == "ERROR":
                self.stats["error_count"] += 1
            elif log["level"] == "CRITICAL":
                self.stats["critical_count"] += 1
    
    def should_analyze(self, new_logs: List[Dict]) -> bool:
        """ë¶„ì„ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        # ìƒˆ ë¡œê·¸ê°€ ì¶©ë¶„íˆ ìŒ“ì˜€ê±°ë‚˜
        if len(new_logs) >= self.thresholds["analysis_trigger"]:
            return True
        
        # ì—ëŸ¬ìœ¨ì´ ì„ê³„ê°’ì„ ë„˜ì—ˆê±°ë‚˜
        if len(new_logs) > 0:
            error_count = sum(1 for log in new_logs if log["level"] in ["ERROR", "CRITICAL"])
            error_rate = error_count / len(new_logs)
            if error_rate >= self.thresholds["error_rate"]:
                return True
        
        # í¬ë¦¬í‹°ì»¬ ë¡œê·¸ê°€ ì„ê³„ê°’ì„ ë„˜ì—ˆê±°ë‚˜
        critical_count = sum(1 for log in new_logs if log["level"] == "CRITICAL")
        if critical_count >= self.thresholds["critical_count"]:
            return True
        
        # ì£¼ê¸°ì  ë¶„ì„ (30ì´ˆë§ˆë‹¤)
        if self.stats["last_analysis"] is None:
            return True
        
        elapsed = (datetime.now() - self.stats["last_analysis"]).total_seconds()
        if elapsed >= self.analysis_interval:
            return True
        
        return False
    
    def run_analysis(self, logs: List[Dict]) -> Dict:
        """ë¡œê·¸ ë¶„ì„ ì‹¤í–‰"""
        print(f"ğŸ” ë¡œê·¸ ë¶„ì„ ì‹¤í–‰ ì¤‘... ({len(logs)}ê°œ ë¡œê·¸)")
        
        # ë¶„ì„í•  ë¡œê·¸ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_log_file = f"temp_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        with open(temp_log_file, 'w', encoding='utf-8') as f:
            for log in logs:
                f.write(log["raw"] + "\n")
        
        try:
            # íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •
            with open("log_llm_pipeline.py", 'r') as f:
                content = f.read()
            
            # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë³€ê²½
            modified_content = content.replace(
                'main("./scenario_1_ë°ì´í„°ë² ì´ìŠ¤_ì˜¤ë¥˜.log", "./analysis_results.json", meta)',
                f'main("./{temp_log_file}", "./temp_analysis_results.json", meta)'
            )
            
            temp_script = f"temp_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            with open(temp_script, 'w') as f:
                f.write(modified_content)
            
            # ë¶„ì„ ì‹¤í–‰
            result = subprocess.run([
                "python3", temp_script
            ], capture_output=True, text=True, cwd=".", timeout=60)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.remove(temp_script)
            os.remove(temp_log_file)
            
            if result.returncode == 0:
                # ê²°ê³¼ ì½ê¸°
                if os.path.exists("temp_analysis_results.json"):
                    with open("temp_analysis_results.json", 'r', encoding='utf-8') as f:
                        analysis_result = json.load(f)
                    os.remove("temp_analysis_results.json")
                    
                    return {
                        "success": True,
                        "timestamp": datetime.now().isoformat(),
                        "log_count": len(logs),
                        "analysis": analysis_result[0]["analysis"] if analysis_result else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
                    }
                else:
                    return {"success": False, "error": "ê²°ê³¼ íŒŒì¼ ì—†ìŒ"}
            else:
                return {"success": False, "error": result.stderr}
                
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "ë¶„ì„ ì‹œê°„ ì´ˆê³¼"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def check_alerts(self, new_logs: List[Dict]):
        """ì•Œë¦¼ ì²´í¬"""
        alerts = []
        
        # ì—ëŸ¬ìœ¨ ì²´í¬
        if len(new_logs) > 0:
            error_count = sum(1 for log in new_logs if log["level"] in ["ERROR", "CRITICAL"])
            error_rate = error_count / len(new_logs)
            if error_rate >= self.thresholds["error_rate"]:
                alerts.append(f"ğŸš¨ ë†’ì€ ì—ëŸ¬ìœ¨: {error_rate:.1%}")
        
        # í¬ë¦¬í‹°ì»¬ ë¡œê·¸ ì²´í¬
        critical_count = sum(1 for log in new_logs if log["level"] == "CRITICAL")
        if critical_count >= self.thresholds["critical_count"]:
            alerts.append(f"ğŸš¨ í¬ë¦¬í‹°ì»¬ ë¡œê·¸ ë‹¤ìˆ˜: {critical_count}ê°œ")
        
        # íŠ¹ì • ì„œë¹„ìŠ¤ ì—ëŸ¬ ì²´í¬
        service_errors = defaultdict(int)
        for log in new_logs:
            if log["level"] in ["ERROR", "CRITICAL"]:
                service_errors[log["service"]] += 1
        
        for service, count in service_errors.items():
            if count >= 5:
                alerts.append(f"ğŸš¨ {service} ì„œë¹„ìŠ¤ ì—ëŸ¬ ë‹¤ìˆ˜: {count}ê°œ")
        
        return alerts
    
    def print_status(self):
        """ìƒíƒœ ì¶œë ¥"""
        print(f"\nğŸ“Š ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ìƒíƒœ")
        print(f"ì´ ë¡œê·¸: {self.stats['total_logs']}ê°œ")
        print(f"ë¶„ì„ íšŸìˆ˜: {self.stats['analysis_count']}íšŒ")
        
        if self.stats['last_analysis']:
            elapsed = (datetime.now() - self.stats['last_analysis']).total_seconds()
            print(f"ë§ˆì§€ë§‰ ë¶„ì„: {elapsed:.0f}ì´ˆ ì „")
        
        print("ë ˆë²¨ë³„ ë¶„í¬:")
        for level, count in self.stats['by_level'].items():
            if count > 0:
                percentage = (count / self.stats['total_logs']) * 100
                print(f"  {level}: {count}ê°œ ({percentage:.1f}%)")
        
        # ìƒìœ„ 3ê°œ ì„œë¹„ìŠ¤
        top_services = sorted(self.stats['by_service'].items(), key=lambda x: x[1], reverse=True)[:3]
        print("ìƒìœ„ ì„œë¹„ìŠ¤:")
        for service, count in top_services:
            if count > 0:
                print(f"  {service}: {count}ê°œ")
    
    def save_analysis_result(self, result: Dict):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        self.analysis_results.append(result)
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = f"monitor_analysis_{timestamp}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ“„ ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_file}")
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        print(f"ğŸ” ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        print(f"ëª¨ë‹ˆí„°ë§ íŒŒì¼: {self.log_file}")
        print(f"ë¶„ì„ ê°„ê²©: {self.analysis_interval}ì´ˆ")
        print("ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        print("-" * 50)
        
        self.running = True
        last_status_time = time.time()
        
        try:
            while self.running:
                # ìƒˆë¡œìš´ ë¡œê·¸ ì½ê¸°
                new_logs = self.read_new_logs()
                
                if new_logs:
                    print(f"ğŸ“ ìƒˆ ë¡œê·¸ {len(new_logs)}ê°œ ê°ì§€")
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.update_stats(new_logs)
                    
                    # ì•Œë¦¼ ì²´í¬
                    alerts = self.check_alerts(new_logs)
                    for alert in alerts:
                        print(alert)
                    
                    # ë¶„ì„ í•„ìš” ì—¬ë¶€ í™•ì¸
                    if self.should_analyze(new_logs):
                        # ìµœê·¼ ë¡œê·¸ë¡œ ë¶„ì„ ì‹¤í–‰
                        analysis_logs = list(self.recent_logs)[-self.window_size:]
                        result = self.run_analysis(analysis_logs)
                        
                        if result["success"]:
                            print("âœ… ë¶„ì„ ì™„ë£Œ")
                            self.save_analysis_result(result)
                        else:
                            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
                        
                        self.stats["analysis_count"] += 1
                        self.stats["last_analysis"] = datetime.now()
                
                # ìƒíƒœ ì¶œë ¥ (30ì´ˆë§ˆë‹¤)
                if time.time() - last_status_time >= 30:
                    self.print_status()
                    last_status_time = time.time()
                
                # 1ì´ˆ ëŒ€ê¸°
                time.sleep(1)
                
        except KeyboardInterrupt:
            print(f"\nğŸ›‘ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨")
        finally:
            self.running = False
            self.print_status()
            
            # ìµœì¢… í†µê³„ ì €ì¥
            stats_file = f"monitor_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(dict(self.stats), f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ“„ ëª¨ë‹ˆí„°ë§ í†µê³„ ì €ì¥: {stats_file}")

def main():
    print("ğŸ” ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ì„¤ì • ì…ë ¥
    log_file = input("ëª¨ë‹ˆí„°ë§í•  ë¡œê·¸ íŒŒì¼ (ê¸°ë³¸: realtime.log): ").strip() or "realtime.log"
    
    try:
        analysis_interval = int(input("ë¶„ì„ ê°„ê²©(ì´ˆ) (ê¸°ë³¸: 30): ").strip() or "30")
    except ValueError:
        analysis_interval = 30
    
    try:
        window_size = int(input("ë¶„ì„ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸: 50): ").strip() or "50")
    except ValueError:
        window_size = 50
    
    # ëª¨ë‹ˆí„° ìƒì„± ë° ì‹œì‘
    monitor = LogMonitor(log_file)
    monitor.analysis_interval = analysis_interval
    monitor.window_size = window_size
    
    monitor.start_monitoring()

if __name__ == "__main__":
    main()
